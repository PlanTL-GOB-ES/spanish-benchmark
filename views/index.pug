extends layout

block title
	title The Spanish Evaluation Benchmark

block description
	meta(name='description', content='The Spaish Evaluation Benchmark (EvalES) is a new reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage. With 100,000+ question-answer pairs on 500+ articles, SQuAD is significantly larger than previous reading comprehension datasets.')

block extralinks
	link(rel='stylesheet', href='./stylesheets/index.css')
	link(rel="stylesheet", href="https://cdn.datatables.net/1.12.1/css/jquery.dataTables.min.css")
	script(async defer src="https://buttons.github.io/buttons.js")
	script(src="https://cdn.datatables.net/1.12.1/js/jquery.dataTables.min.js")
	script(src="./javascripts/mi_script.js")


block content
	.cover#contentCover
		.container
			.row
				.col-md-15
					.infoCard
						.infoBody
							.infoHeadline
								h2 Leaderboard
							p.spaced EvalES tests the ability of a system in the Spanish language. Below are the results of the different models.
							div#leaderboard

							br
							p#sendResults
								a(href="./submit.html")
									button.submitButton SEND YOUR RESULTS

				.col-md-15
					.infoCard
						.infoBody
							.infoHeadline
								h2 What is EvalES?
							p The EvalES benchmark consists of 7 tasks: Named Entity Recognition and Classification (CoNLL-NERC), Part-of-Speech Tagging (UD-POS), Text Classification (MLDoc), Paraphrase Identification (PAWS-X), Semantic Textual Similarity (STS), Question Answering (SQAC), and Textual Entailment (XNLI).
							br
							p For questions or comments, please contact us at 
								a(href="mailto:plantl-gob-es@bsc.es") plantl-gob-es@bsc.es
								| .
						.infoSubheadline
							include includes/tweet
							include includes/github
