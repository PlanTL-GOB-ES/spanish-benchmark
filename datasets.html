<!DOCTYPE html><!--Author: BSC - TeMU 2022--><html><head><meta charset="utf-8"><title>Datasets - The Spanish Evaluation Benchmark</title><meta name="description" content="The Spaish Evaluation Benchmark (EvalES) is a new reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage. With 100,000+ question-answer pairs on 500+ articles, SQuAD is significantly larger than previous reading comprehension datasets."><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no"><meta property="og:image" content="./logo.png"><link rel="image_src" type="image/png" href="./logo.png"><link rel="shortcut icon" href="./favicon.ico" type="image/x-icon"><link rel="icon" href="./favicon.ico" type="image/x-icon"><link rel="stylesheet" href="./bower_components/bootstrap/dist/css/bootstrap.min.css"><link rel="stylesheet" href="./stylesheets/layout.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20,400,0,0"><script src="./javascripts/analytics.js"></script><script src="./bower_components/jquery/dist/jquery.min.js"></script><script src="./bower_components/bootstrap/dist/js/bootstrap.min.js"></script><link rel="stylesheet" href="./stylesheets/index.css"><script src="./javascripts/navbar-prevent-on-html-link.js"></script></head><body><div class="navbar navbar-default navbar-fixed-top" id="topNavbar" role="navigation"><div class="container clearfix" id="navContainer"><div class="rightNav"><div class="collapseDiv"><button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar"><span class="glyphicon glyphicon-menu-hamburger"></span></button></div><div class="collapse navbar-collapse" id="navbar"><ul class="nav navbar-nav navbar-right"><li><a href="./">Home</a></li><li><a href="./datasets.html">Datasets</a></li><li><a href="./submit.html">Submit</a></li></ul></div></div><div class="leftNav"><div class="brandDiv"><a class="navbar-brand" href="./">EvalES</a></div></div></div></div><div class="cover" id="topCover"><div class="container"><div class="row"><div class="col-md-12"><h1 id="appTitle">Eval<b>ES</b></h1><h2 id="appSubtitle">The Spanish Evaluation Benchmark</h2></div></div></div></div><div class="cover" id="contentCover"><div class="container"><div class="row"><div class="col-md-15"><div class="infoCard"><div class="infoBody"><div class="infoHeadline"></div><h2>Datasets</h2><div class="datasetHolder" id="conll-nerc"><h3>CoNLL Named Entity Recognition and Classification (CoNLL-NERC)</h3><p>The Spanish dataset of the CoNLL-2002 Shared Task (Tjong Kim Sang, 2002). The dataset is annotated with four types of named entities --persons, locations, organizations, and other miscellaneous entities-- formatted in the standard Beginning-Inside-Outside (BIO) format. The corpus consists of 8,324 train sentences with 19,400 named entities, 1,916 development sentences with 4,568 named entities, and 1,518 test sentences with 3,644 named entities.</p></div><div class="datasetHolder" id="capitel-nerc"><h3>CAPITEL Named Entity Recognition and Classification (CAPITEL-NERC)</h3><p>The dataset of the first sub-task of the CAPITEL-EVAL shared task at IberLEF 2020. The source of the CAPITEL-NERC dataset is the CAPITEL corpus (Porta-Zamorano and Espinosa-Anke, 2020), a collection of Spanish articles in the news domain. CAPITEL-NERC is annotated with the same four named entities used in CoNLL-NERC (persons, locations, organizations, and other miscellaneous entities), but following a Beginning-Inside-Outside-Ending-Single (BIOES) format.The corpus consists of 22,647 train sentences with 31,311 named entities, and 7,550 sentences for thr development and test sets respectively, with 10,229 named entities for the development set, and 10,226 for the test set.</p></div><div class="datasetHolder" id="ud-pos"><h3>Universal Dependencies Part-of-Speech Tagging (UD-POS)</h3><p>The Universal Dependencies Part-of-Speech dataset from the Spanish AnCora corpus (Taulé, Martí, and Recasens, 2008).</p></div><div class="datasetHolder" id="capitel-pos"><h3>CAPITEL Part-of-Speech Tagging (CAPITEL-POS)</h3><p>The Part-of-Speech from the CAPITEL corpus (Porta-Zamorano and Espinosa-Anke, 2020).</p></div><div class="datasetHolder" id="mldoc"><h3>Multilingual Document Classification Corpus (MLDoc)</h3><p>The Multilingual Document Classification Corpus (MLDoc) (Schwenk and Li, 2018; Lewis et al., 2004) is a cross-lingual document classification dataset covering 8 languages. We used the Spanish portion to evaluate our models on monolingual classification. The corpus consists of 14,458 news articles from Reuters classified in four categories: Corporate/Industrial, Economics, Government/Social and Markets.</p></div><div class="datasetHolder" id="paws-x"><h3>Paraphrase Identification (PAWS-X)</h3><p>The Crosslingual Adversarial Dataset for Paraphrase Identification (PAWS-X) (Yang et al., 2019) is a multilingual dataset that contains 49,401 training sentences, 2,000 sentences for the development set, and another 2,000 for the test set. It is important to note that this dataset contains machine translated text, and as a consequence some of the Spanish sentences might not be entirely correct.</p></div><div class="datasetHolder" id="sts"><h3>Semantic Textual Similarity (STS)</h3><p>We collected the Spanish test sets from 2014 (Agirre et al., 2014) and 2015 (Agirre et al., 2015). Since no training data was provided for the Spanish subtask, we randomly sampled both datasets into 1,321 sentences for the train set, 78 sentences for the development set, and 156 sentences for the test set. To make the task harder for the models, we purposely made the development set smaller than the test set.</p></div><div class="datasetHolder" id="sqac"><h3>Question Answering (SQAC)</h3><p>A new extractive QA dataset in Spanish created from texts extracted from the Spanish Wikipedia, encyclopedic articles, newswire articles from Wikinews, and the Spanish section of the AnCora corpus. The corpus consists of 18,817 questions and the annotation of their answer spans from 6,247 textual contexts.</p></div><div class="datasetHolder" id="xnli"><h3>Cross-Lingual NLI Corpus (XNLI)</h3><p>The Spanish part of the Cross-Lingual NLI Corpus (XNLI) (Conneau et al., 2018). This evaluation corpus consists of a collection 400,202 sentences, annotated with textual entailment via crowdsourcing.</p></div></div></div></div></div></div></div><nav class="navbar navbar-default navbar-static-bottom footer"><div class="container clearfix"><div class="centerNav"><div><img src="./gob-es.png"><img src="./secretaria-es.png"></div></div></div></nav></body></html>