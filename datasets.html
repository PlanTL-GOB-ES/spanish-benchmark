<!DOCTYPE html><!--Author: BSC - TeMU 2022--><html><head><meta charset="utf-8"><title>Datasets - The Spanish Evaluation Benchmark</title><meta name="description" content="The Spaish Evaluation Benchmark (EvalES) is a new reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage. With 100,000+ question-answer pairs on 500+ articles, SQuAD is significantly larger than previous reading comprehension datasets."><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no"><meta property="og:image" content="./logo.png"><link rel="image_src" type="image/png" href="./logo.png"><link rel="shortcut icon" href="./favicon.ico" type="image/x-icon"><link rel="icon" href="./favicon.ico" type="image/x-icon"><link rel="stylesheet" href="./bower_components/bootstrap/dist/css/bootstrap.min.css" media="screen"><link rel="stylesheet" href="./stylesheets/layout.css" media="screen"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20,400,0,0" media="screen"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/orestbida/cookieconsent@v2.8.6/dist/cookieconsent.css" media="print" onload="this.media='all'"><script src="./bower_components/jquery/dist/jquery.min.js" defer"></script>
<script src="./bower_components/bootstrap/dist/js/bootstrap.min.js" defer></script>
<link rel="stylesheet" href="./stylesheets/index.css"><script src="./javascripts/navbar-prevent-on-html-link.js"></script><!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-F562BRVWX9"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-F562BRVWX9');
</script>
</head><body><div class="navbar navbar-default navbar-fixed-top" id="topNavbar" role="navigation"><div class="container clearfix" id="navContainer"><div class="rightNav"><div class="collapseDiv"><button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar"><span class="glyphicon glyphicon-menu-hamburger"></span></button></div><div class="collapse navbar-collapse" id="navbar"><ul class="nav navbar-nav navbar-right"><li><a href="./">Home</a></li><li><a href="./datasets.html">Datasets</a></li><li><a href="./submit.html">Submit</a></li></ul></div></div><div class="leftNav"><div class="brandDiv"><a class="navbar-brand" href="./">EvalES</a></div></div></div></div><div class="cover" id="topCover"><div class="container"><div class="row"><div class="col-md-12"><h1 id="appTitle">Eval<b>ES</b></h1><h2 id="appSubtitle">The Spanish Evaluation Benchmark</h2></div></div></div></div><div class="cover" id="contentCover"><div class="container"><div class="row"><div class="col-md-15"><div class="infoCard"><div class="infoBody"><h2>Datasets</h2><div class="datasetHolder" id="description"><h3>What is EvalEs?</h3><p>The EvalES benchmark consists of 7 tasks: Named Entity Recognition and Classification (CoNLL-NERC), Part-of-Speech Tagging (UD-POS), Text Classification (MLDoc), Paraphrase Identification (PAWS-X), Semantic Textual Similarity (STS), Question Answering (SQAC), and Textual Entailment (XNLI).</p></div><div class="datasetHolder" id="nerc"><h3><a href="https://huggingface.co/datasets/PlanTL-GOB-ES/CoNLL-NERC-es" target="_blank">CoNLL-NERC</a></h3><p>CoNLL-NERC is the Spanish dataset of the CoNLL-2002 Shared Task (Tjong Kim Sang, 2002). The dataset is annotated with four types of named entities --persons, locations, organizations, and other miscellaneous entities-- formatted in the standard Beginning-Inside-Outside (BIO) format. The corpus consists of 8,324 train sentences with 19,400 named entities, 1,916 development sentences with 4,568 named entities, and 1,518 test sentences with 3,644 named entities.</p></div><div class="datasetHolder" id="pos"><h3><a href="https://huggingface.co/datasets/PlanTL-GOB-ES/UD_Spanish-AnCora" target="_blank">UD-POS</a></h3><p>UD-POS comes from the AnCora corpus, projected on the Universal Dependencies treebank. The original annotation was done in a constituency framework as a part of the AnCora project at the University of Barcelona (Taulé, Martí, and Recasens, 2008). It was converted to dependencies by the Universal Dependencies team and used in the CoNLL 2009 shared task. The CoNLL 2009 version was later converted to HamleDT and to Universal Dependencies.</p></div><div class="datasetHolder" id="mldoc"><h3><a href="https://huggingface.co/datasets/PlanTL-GOB-ES/MLDoc" target="_blank">MLDoc</a></h3><p>For document classification, we use the Multilingual Document Classification Corpus (MLDoc) (Schwenk and Li, 2018; Lewis et al., 2004), a cross-lingual document classification dataset covering 8 languages. We use the Spanish portion to evaluate our models on monolingual classification. The corpus consists of 14,458 news articles from Reuters classified in four categories: Corporate/Industrial, Economics, Government/Social and Markets.</p></div><div class="datasetHolder" id="pawsx"><h3><a href="https://huggingface.co/datasets/paws-x" target="_blank">PAWS-X</a></h3><p>For paraphrase identification, we use the Cross-lingual Adversarial Dataset for Paraphrase Identification (PAWS-X) (Yang et al., 2019), a multilingual dataset that contains 49,401 training sentences, 2,000 sentences for the development set, and 2,000 sentences for the test set. It is important to note that this dataset contains machine translated text, and as a consequence some of the Spanish sentences might not be entirely correct.</p></div><div class="datasetHolder" id="sts"><h3><a href="https://huggingface.co/datasets/PlanTL-GOB-ES/sts-es" target="_blank">STS</a></h3><p>For Semantic Text Similarity, we collected the Spanish test sets from SemEval-2014 (Agirre et al., 2014) and SemEval-2015 (Agirre et al., 2015). Since no training data was provided for the Spanish subtask, we randomly sampled both datasets into 1,321 sentences for the train set, 78 sentences for the development set, and 156 sentences for the test set. To make the task harder for the models, we purposely made the development set smaller than the test set.</p></div><div class="datasetHolder" id="sqac"><h3><a href="https://huggingface.co/datasets/PlanTL-GOB-ES/SQAC" target="_blank">SQAC</a></h3><p>For Question Answering, we built a new extractive QA dataset in Spanish created from texts extracted from the Spanish Wikipedia, encyclopedic articles, newswire articles from Wikinews, and the Spanish section of the AnCora corpus. The corpus consists of 18,817 questions and the annotation of their answer spans from 6,247 textual contexts.</p></div><div class="datasetHolder" id="xnli"><h3><a href="https://huggingface.co/datasets/xnli" target="_blank">XNLI</a></h3><p>For Textual Entailment, we use the Spanish part of the Cross-Lingual NLI Corpus (XNLI) (Conneau et al., 2018). This evaluation corpus consists of a collection 400,202 sentences, annotated with textual entailment via crowdsourcing.</p></div></div></div></div></div></div></div><footer><div class="footer-custom-images"><a target="_blank" title="Barcelona Supercomputing Center" href="https://www.bsc.es"><img id="bsclogo" alt="BSC logo" src="./images/BSC-blue-small.png"></a><a target="_blank" title="Plan de Impulso de las Tecnologías del Lenguaje" href="https://plantl.mineco.gob.es/Paginas/index.aspx"><img alt="Plan TL logo" src="./images/plantl.png"></a><a target="_blank" title="Ministerio de Asuntos Económicos y Transformación Digital" href="https://portal.mineco.gob.es/en-us/Pages/index.aspx"><img alt="Mineco logo" src="./images/gob-es.png"></a><a target="_blank" title="Digitalisation and Artificial Intelligence - Telecommunications and Digital Infrastructure" href="https://avancedigital.mineco.gob.es/en-us/Paginas/index.aspx"><img alt="SEAD logo" src="./images/secretaria-es.png"></a></div></footer><script src="https://cdn.jsdelivr.net/gh/orestbida/cookieconsent@v2.8.6/dist/cookieconsent.js" defer></script>
<script src="./javascripts/cookieconsent-init-min.js" defer></script>
</body></html>