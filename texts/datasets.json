{
    "conll-nerc": {
        "title": "CoNLL Named Entity Recognition and Classification (CoNLL-NERC)",
        "text":"The Spanish dataset of the CoNLL-2002 Shared Task (Tjong Kim Sang, 2002). The dataset is annotated with four types of named entities --persons, locations, organizations, and other miscellaneous entities-- formatted in the standard Beginning-Inside-Outside (BIO) format. The corpus consists of 8,324 train sentences with 19,400 named entities, 1,916 development sentences with 4,568 named entities, and 1,518 test sentences with 3,644 named entities.",
        "id": "conll-nerc"
    },
    "capitel-nerc": {
        "title": "CAPITEL Named Entity Recognition and Classification (CAPITEL-NERC)",
        "text":"The dataset of the first sub-task of the CAPITEL-EVAL shared task at IberLEF 2020. The source of the CAPITEL-NERC dataset is the CAPITEL corpus (Porta-Zamorano and Espinosa-Anke, 2020), a collection of Spanish articles in the news domain. CAPITEL-NERC is annotated with the same four named entities used in CoNLL-NERC (persons, locations, organizations, and other miscellaneous entities), but following a Beginning-Inside-Outside-Ending-Single (BIOES) format.The corpus consists of 22,647 train sentences with 31,311 named entities, and 7,550 sentences for thr development and test sets respectively, with 10,229 named entities for the development set, and 10,226 for the test set.",
        "id": "capitel-nerc"
    },
    "ud-pos": {
        "title": "Universal Dependencies Part-of-Speech Tagging (UD-POS)",
        "text": "The Universal Dependencies Part-of-Speech dataset from the Spanish AnCora corpus (Taulé, Martí, and Recasens, 2008).",
        "id": "ud-pos"
    },
    "capitel-pos": {
        "title": "CAPITEL Part-of-Speech Tagging (CAPITEL-POS)",
        "text": "The Part-of-Speech from the CAPITEL corpus (Porta-Zamorano and Espinosa-Anke, 2020).",
        "id": "capitel-pos"
    },
    "mldoc": {
        "title": "Multilingual Document Classification Corpus (MLDoc)",
        "text": "The Multilingual Document Classification Corpus (MLDoc) (Schwenk and Li, 2018; Lewis et al., 2004) is a cross-lingual document classification dataset covering 8 languages. We used the Spanish portion to evaluate our models on monolingual classification. The corpus consists of 14,458 news articles from Reuters classified in four categories: Corporate/Industrial, Economics, Government/Social and Markets.",
        "id": "mldoc"
    },
    "paws-x": {
        "title": "Paraphrase Identification (PAWS-X)",
        "text": "The Crosslingual Adversarial Dataset for Paraphrase Identification (PAWS-X) (Yang et al., 2019) is a multilingual dataset that contains 49,401 training sentences, 2,000 sentences for the development set, and another 2,000 for the test set. It is important to note that this dataset contains machine translated text, and as a consequence some of the Spanish sentences might not be entirely correct.",
        "id": "paws-x"
    },
    "sts": {
        "title": "Semantic Textual Similarity (STS)",
        "text": "We collected the Spanish test sets from 2014 (Agirre et al., 2014) and 2015 (Agirre et al., 2015). Since no training data was provided for the Spanish subtask, we randomly sampled both datasets into 1,321 sentences for the train set, 78 sentences for the development set, and 156 sentences for the test set. To make the task harder for the models, we purposely made the development set smaller than the test set.",
        "id": "sts"
    },
    "sqac": {
        "title": "Question Answering (SQAC)",
        "text": "A new extractive QA dataset in Spanish created from texts extracted from the Spanish Wikipedia, encyclopedic articles, newswire articles from Wikinews, and the Spanish section of the AnCora corpus. The corpus consists of 18,817 questions and the annotation of their answer spans from 6,247 textual contexts.",
        "id": "sqac"
    },
    "xnli": {
        "title": "Cross-Lingual NLI Corpus (XNLI)",
        "text": "The Spanish part of the Cross-Lingual NLI Corpus (XNLI) (Conneau et al., 2018). This evaluation corpus consists of a collection 400,202 sentences, annotated with textual entailment via crowdsourcing.",
        "id": "xnli"
    }
}
